---
title: 'NLP : TripAdvisor Recommendation Challenge'
publishDate: 2024-11-30 00:00:00
img: /assets/NLP_BM25.jpg
img_alt: NLP vs BM25, TripAdvisor Recommendation Challenge.
description: |
  
tags:
  - NLP
  - Embedding
---

### üéØ Contexte & Objectif
#### ¬∑ Pr√©sentation du probl√®me
L'algorithme **BM25**, une am√©lioration de TF-IDF, reste une des approches les plus performantes pour la recherche d'information bas√©e sur les mots-cl√©s. Cependant, cette m√©thode se base principalement sur la fr√©quence et la raret√© des mots, sans capturer le sens s√©mantique profond du texte.

#### ¬∑ Int√©r√™t du projet
Le d√©fi est de d√©velopper un syst√®me de recommandation d'h√¥tels plus pertinent que BM25, en se basant uniquement sur le contenu textuel des avis clients. L'objectif est de proposer des lieux similaires non pas par les mots qu'ils partagent, mais par le sens et les exp√©riences d√©crites dans les commentaires.

#### ¬∑ Objectif final √† atteindre
L'objectif est de construire un mod√®le non supervis√© qui, pour un h√¥tel donn√©, recommande l'h√¥tel le plus similaire en se basant sur ses avis. La performance sera mesur√©e en comparant les notes moyennes (sur des aspects comme la propret√©, le service, etc.) entre l'h√¥tel de la requ√™te et l'h√¥tel recommand√©. **Le but est d'obtenir une Erreur Quadratique Moyenne (MSE) inf√©rieure √† celle du mod√®le de r√©f√©rence BM25.**

***

### üß∞ Donn√©es
#### ¬∑ Source des donn√©es
Le projet utilise le jeu de donn√©es **"TripAdvisor Hotel Reviews"** disponible sur Kaggle. Il contient des centaines de milliers d'avis d'h√¥tels.
[Lien vers le dataset sur Kaggle](https://www.kaggle.com/datasets/joebeachcapital/hotel-reviews/data)

#### ¬∑ Volume et structure
Le jeu de donn√©es initial a √©t√© filtr√© pour ne conserver que les avis poss√©dant des notes sur un ensemble strict de 7 aspects ("service", "cleanliness", "overall", etc.), ce qui a permis de garder **436 356 avis pertinents**. Pour la mod√©lisation, un √©chantillon de **5000 avis** a √©t√© cr√©√©, correspondant √† 50 avis pour 100 h√¥tels diff√©rents, afin d'avoir un corpus de travail √©quilibr√©.

#### ¬∑ Type de variables
-   **Texte :** Les colonnes `title` et `text` ont √©t√© fusionn√©es en une seule colonne `avis` pour former le corpus de chaque h√¥tel.
-   **Identifiants :** `offering_id` pour identifier chaque h√¥tel.
-   **Notes (pour √©valuation uniquement) :** Les notes moyennes pour chaque aspect (`avg_service`, `avg_cleanliness`, etc.) ont √©t√© calcul√©es par h√¥tel et utilis√©es exclusivement pour mesurer la MSE du mod√®le. Le mod√®le lui-m√™me n'a pas acc√®s √† ces notes pendant la recommandation.

***

### üß™ M√©thodologie
#### ¬∑ Feature Engineering & Mod√©lisation
Plusieurs approches ont √©t√© test√©es pour battre la baseline BM25.

1.  **Baseline : BM25**
    -   Une impl√©mentation standard de BM25 a √©t√© utilis√©e comme mod√®le de r√©f√©rence. Cette m√©thode fonctionne en tokenisant le texte et en calculant un score de pertinence bas√© sur la fr√©quence des termes (TF-IDF).

2.  **Approche 1 : Word Embedding avec Word2Vec**
    -   **Pr√©traitement :**
        1.  Retrait des stopwords, de la ponctuation et mise en minuscules.
        2.  S√©paration des avis en tokens (mots).
    -   **Vectorisation :**
        1.  Un mod√®le **Word2Vec** est entra√Æn√© sur l'ensemble des tokens du corpus pour apprendre une repr√©sentation vectorielle pour chaque mot.
        2.  Le vecteur associ√© √† chaque mot du vocabulaire est calcul√© par le mod√®le.
        3.  Pour chaque avis, un vecteur global est obtenu en calculant la **moyenne des vecteurs de tous les mots** qui le composent.

3.  **Approche 2 : Sentence Embedding avec Sentence-Transformers**
    -   **Vectorisation S√©mantique :**
        1.  Le mod√®le pr√©-entra√Æn√© **`all-MiniLM-L6-v2`** est utilis√© pour transformer directement chaque phrase des avis en un vecteur s√©mantique.
        2.  Le vecteur global d'un avis est ensuite calcul√© en faisant la moyenne des vecteurs de ses phrases.

#### ¬∑ Strat√©gies de Recommandation Test√©es
Pour chaque m√©thode d'embedding (Word Embedding et Sentence Embedding), quatre strat√©gies de pr√©diction ont √©t√© √©valu√©es pour trouver la plus performante :

1.  **Niveau Avis - Distance Euclidienne :** trouver l'avis le plus proche en utilisant la plus petite distance euclidienne.
2.  **Niveau Avis - Similarit√© Cosinus :** trouver l'avis le plus proche en utilisant la plus grande similarit√© cosinus.
3.  **Niveau √âtablissement - Distance Euclidienne :** calculer le vecteur moyen par h√¥tel, puis trouver l'h√¥tel le plus proche via la plus petite distance euclidienne entre ces vecteurs moyens.
4.  **Niveau √âtablissement - Similarit√© Cosinus :** calculer le vecteur moyen par h√¥tel, puis trouver l'h√¥tel le plus proche via la plus grande similarit√© cosinus.

#### ¬∑ √âvaluation
Le protocole d'√©valuation pour chaque strat√©gie est le suivant :
-   Chaque avis du jeu de test est soumis au mod√®le comme requ√™te.
-   Le mod√®le retourne l'h√¥tel qu'il juge le plus similaire.
-   On calcule l'**Erreur Quadratique Moyenne (MSE)** entre les 7 notes moyennes de l'h√¥tel-requ√™te et celles de l'h√¥tel retourn√©.
-   Le score final est la moyenne de toutes les MSE calcul√©es. **Un score plus bas signifie un meilleur mod√®le.**

***

### üìä R√©sultats
#### ¬∑ Performances des mod√®les
Les r√©sultats de l'√©valuation ont montr√© qu'une des approches bas√©es sur les embeddings s√©mantiques √©tait significativement plus performante que la baseline.
-   **MSE (BM25) :** `1.91`
-   **MSE (Meilleure Approche : Sentence-Transformers + distance euclidienne au niveau avis) :** `1.05`
-   **MSE (autres approches):** `1.12 - 1.28`

#### ¬∑ Comparaison des approches
L'approche avec **Sentence-Transformers a battu la baseline BM25**, en obtenant une MSE inf√©rieure de pr√®s de 45%. L'exp√©rimentation a montr√© que l'agr√©gation des vecteurs au niveau de l'avis et l'utilisation de la distance euclidienne donnaient les meilleurs r√©sultats. Cependant, les autres approches ont tout de m√™me montr√© de meilleures performances que BM25.

#### ¬∑ Interpr√©tation des r√©sultats
La sup√©riorit√© du mod√®le d'embedding s'explique par sa capacit√© √† capturer le **sens** et le **contexte** des avis, plut√¥t que de se limiter √† la surface lexicale. Deux h√¥tels peuvent √™tre jug√©s similaires s'ils √©voquent des exp√©riences similaires m√™me s'ils n'utilisent pas exactement les m√™mes mots.

***

### üí° Ce que j'ai appris
#### ¬∑ Comp√©tences acquises ou renforc√©es
-   **Recherche d'Information :** Impl√©mentation et √©valuation d'un mod√®le de r√©f√©rence classique (BM25).
-   **Pr√©traitement de Texte :** Application de techniques de nettoyage de texte (lemmatisation, stopwords) adapt√©es √† un corpus d'avis clients.
-   **NLP & S√©mantique :** Utilisation de mod√®les de transformers pr√©-entra√Æn√©s (`Sentence-Transformers`) et de mod√®les personnalis√©s (`Word2Vec`) pour g√©n√©rer des embeddings de texte et effectuer de la recherche par similarit√© s√©mantique.

