---
title: '√âtude Comparative : Ensemble Learning vs Algorithmes √âvolutionnaires' 
publishDate: 2024-10-30 00:00:00
img: /assets/comparative_study.jpg
img_alt: √âtude Comparative Ensemble Learning vs Algorithmes √âvolutionnaires
description: |
tags:  
  - Ensemble learning  
  - DEAP  
---

### üéØ Contexte & Objectif
#### ¬∑ Pr√©sentation du probl√®me
En physique des particules, la d√©tection du boson de Higgs est un probl√®me de classification fondamental. Apr√®s des collisions de particules √† haute √©nergie, il est crucial de distinguer les √©v√©nements "signaux" (indiquant la pr√©sence d'un boson de Higgs) du "bruit de fond". Ce projet s'attaque √† ce d√©fi en utilisant des techniques de Machine Learning avanc√©es pour automatiser et fiabiliser cette classification.

#### ¬∑ Int√©r√™t du projet
Ce projet explore et compare deux familles de m√©thodes de Machine Learning pour un probl√®me de classification complexe. L'objectif est de comprendre leurs forces, faiblesses et compromis respectifs, non seulement en termes de performance pure, mais aussi d'efficacit√© de calcul et d'interpr√©tabilit√© des mod√®les.

#### ¬∑ Objectif final √† atteindre
L'objectif principal est de mettre en ≈ìuvre, d'√©valuer et de comparer :
1.  Les techniques d'**Ensemble learning** (Bagging et Boosting).
2.  L'**Apprentissage √âvolutionnaire** (Programmation G√©n√©tique avec DEAP).
L'analyse comparative se base sur leurs performances sur le jeu de donn√©es de d√©tection du Boson de Higgs.

***

### üß∞ Donn√©es
#### ¬∑ Source des donn√©es
Les donn√©es proviennent du jeu de donn√©es public **"Higgs Boson Machine Learning Challenge"** disponible sur Kaggle. Il contient des caract√©ristiques de haut niveau d√©riv√©es de simulations de collisions de particules.
[Lien vers le dataset sur Kaggle](https://www.kaggle.com/competitions/higgs-boson/data)

#### ¬∑ Volume et structure
Le jeu de donn√©es complet contient plus de 800 000 √©v√©nements. Pour ce projet, une analyse a √©t√© men√©e sur un **√©chantillon d'environ 80 000 observations**.

#### ¬∑ Type de variables
- **Identifiant :** `EventId`.
- **Num√©riques (Physique des particules) :** 30 caract√©ristiques primitives (`PRI_*`) et d√©riv√©es (`DER_*`) de type `float64`.
- **Cible :** `Label`, une variable binaire ('s' pour signal, 'b' pour bruit de fond), transform√©e en 0 et 1.

***

### üß™ M√©thodologie
#### ¬∑ Exploration et nettoyage des donn√©es
Pr√©traitement des donn√©es :
- Suppression des colonnes non informatives.
- Gestion des valeurs manquantes (-999.0), remplac√©es par la **moyenne** de chaque colonne via `SimpleImputer`.
- **Normalisation** des caract√©ristiques num√©riques √† l'aide d'un `MinMaxScaler` pour les ramener entre 0 et 1.

#### ¬∑ Feature Engineering
Une **Analyse en Composantes Principales (PCA)** a √©t√© appliqu√©e pour r√©duire la dimensionnalit√© des donn√©es, en conservant 90% de la variance expliqu√©e, r√©duisant ainsi l'espace des caract√©ristiques pour am√©liorer l'efficacit√© computationnelle.

#### ¬∑ Mod√©lisation et Comparaison  
**M√©thodes d'Ensemble test√©es :**
- **Bagging :** 
  - Bagging avec Random Forest 
  - Bagging avec Logistic Regression
  - Bagging avec GaussianNB 
- **Boosting :** 
  - AdaBoost 
  - Gradient Boosting 

**Apprentissage √âvolutionnaire :**
- Impl√©mentation avec la biblioth√®que **DEAP** utilisant la programmation g√©n√©tique
- **Grid Search** extensive avec 8 combinaisons de param√®tres pour chaque algorithme (M√©triques d'optimisation : accuracy et f1_score).
- Algorithmes test√©s : `eaSimple` et `eaMuPlusLambda`

#### ¬∑ √âvaluation
Les performances de chaque mod√®le ont √©t√© √©valu√©es sur un jeu de test (30% des donn√©es) en utilisant les m√©triques suivantes :
- **Accuracy**
- **Precision & Recall**
- **F1-Score**
- **Temps d'entra√Ænement**

***

### üìä R√©sultats

#### ¬∑ Performances des mod√®les d'ensemble

**Gradient Boosting** s'impose comme le leader avec **71.5% d'accuracy** et **57.8% de F1-Score**, d√©montrant la sup√©riorit√© des techniques de boosting pour ce probl√®me complexe. 

**Bagging avec Random Forest** se distingue par son excellent compromis performance/efficacit√©, atteignant **69.2% d'accuracy** en seulement **3 secondes**, soit 5 fois plus rapide que Gradient Boosting.

Les autres mod√®les d'ensemble (AdaBoost, Bagging LR, Bagging Gauss) montrent des performances interm√©diaires entre 64% et 68% d'accuracy.

#### ¬∑ Performances DEAP

L'apprentissage √©volutionnaire r√©v√®le des r√©sultats plus contrast√©s. Sur **32 configurations test√©es**, la performance moyenne atteint **66.7% d'accuracy** et **43.6% de F1-Score**.

La **configuration optimale** (eaMuPlusLambda avec optimisation F1) rivalise avec les meilleurs mod√®les d'ensemble en atteignant **65.2% d'accuracy** et **56.3% de F1-Score**, mais au prix d'un temps d'ex√©cution de **614 secondes**.

#### ¬∑ Comparaison globale

**Gradient Boosting domine** avec le meilleur F1-Score (0.578), suivi de pr√®s par la **configuration DEAP optimale** (0.563). Cependant, les **m√©thodes d'ensemble sont 20 √† 200 fois plus rapides** que DEAP.

**Bagging Random Forest** √©merge comme la **solution la plus √©quilibr√©e**, offrant 92% de la performance de Gradient Boosting en seulement 20% du temps d'ex√©cution.

**Tous les mod√®les souffrent du d√©s√©quilibre des classes**, particuli√®rement visible dans les m√©triques de recall qui restent modestes.

***

### üí° Ce que j'ai appris
#### ¬∑ Comp√©tences acquises ou renforc√©es
- **Pr√©traitement de Donn√©es :** Ma√Ætrise compl√®te du pipeline de nettoyage, normalisation et r√©duction de dimensionnalit√© (PCA).
- **Apprentissage d'Ensemble :** Impl√©mentation et comparaison de techniques de **Bagging** et de **Boosting**.
- **Apprentissage √âvolutionnaire :** Application approfondie de la biblioth√®que **DEAP** avec programmation g√©n√©tique, incluant la d√©finition de primitives, fonctions de fitness et grid search.
- **Optimisation d'Hyperparam√®tres :** Mise en ≈ìuvre d'une recherche exhaustive sur 32 configurations pour identifier les param√®tres optimaux.
- **Analyse Comparative :** √âvaluation des compromis entre performance pr√©dictive, efficacit√© computationnelle et robustesse pour des familles d'algorithmes distinctes.
