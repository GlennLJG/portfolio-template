---
title: 'ML : Maintenance pr√©dictive d‚Äô√©quipement industriel'
publishDate: 2025-01-22 00:00:00
img: /assets/ML_maintenance_predictive.jpg
img_alt: ML_maintenance_predictive
description: |
tags:
  - Imbalanced data
  - Ensemble learning
  - Time series
---

### üéØ Contexte & Objectif
#### ¬∑ Pr√©sentation du besoin m√©tier
Dans le secteur industriel, les pannes de machines impr√©vues entra√Ænent des temps d'arr√™t co√ªteux, des retards de production et des risques de s√©curit√©. L'objectif de la maintenance pr√©dictive est de passer d'une approche r√©active (r√©parer apr√®s la panne) √† une strat√©gie proactive, en anticipant les d√©faillances pour optimiser les plannings de maintenance.
Ce projet vise √† construire un syst√®me de maintenance pr√©dictive intelligent pour les √©quipements industriels. En pr√©disant les pannes avant qu'elles ne surviennent, on peut r√©duire les temps d'arr√™t, minimiser les co√ªts de maintenance et augmenter la dur√©e de vie et la fiabilit√© des √©quipements. Le d√©fi principal r√©side dans la raret√© des √©v√©nements de panne, ce qui cr√©e des jeux de donn√©es fortement d√©s√©quilibr√©s.

#### ¬∑ Objectif final √† atteindre
D√©velopper un mod√®le de machine learning performant capable de pr√©dire la d√©faillance d'un √©quipement (ici, un disque dur) dans une fen√™tre de temps d√©finie, en se basant sur les donn√©es de capteurs historiques. Le mod√®le doit √™tre particuli√®rement efficace pour identifier les pannes (la classe minoritaire), malgr√© leur faible fr√©quence.

***

### üß∞ Donn√©es
#### ¬∑ Source des donn√©es
Les donn√©es utilis√©es proviennent du jeu de donn√©es public **"Hard Drive Test Data" de Backblaze**, disponible sur Kaggle. Ce dataset contient les relev√©s S.M.A.R.T. quotidiens de dizaines de milliers de disques durs en op√©ration.
[Lien vers le dataset sur Kaggle](https://www.kaggle.com/datasets/backblaze/hard-drive-test-data)

#### ¬∑ Volume et structure
Le jeu de donn√©es complet est massif, contenant des millions d'enregistrements. Pour ce projet, une analyse est men√©e sur un sous-ensemble pertinent (donn√©es sur un mois), repr√©sentant **1 897 482 observations** avant la cr√©ation de s√©quences temporelles. La structure est une s√©rie temporelle o√π chaque ligne est un snapshot journalier des indicateurs S.M.A.R.T. pour un disque dur unique.

#### ¬∑ Type de variables
- **Identifiants/Temporelles :** `date`, `serial_number`.
- **Cat√©gorielles :** `model`.
- **Num√©riques (Capteurs) :** Une multitude de variables `smart_..._raw` (ex: `smart_5_raw` - Reallocated Sectors Count) qui sont les indicateurs bruts de sant√©.
- **Cible :** `failure` (variable binaire, 1 pour une panne, 0 pour une op√©ration normale).

***

### üß™ M√©thodologie
#### ¬∑ Exploration et nettoyage des donn√©es (EDA)
Une analyse exploratoire a √©t√© men√©e pour comprendre la distribution des features, identifier les corr√©lations et visualiser le d√©s√©quilibre extr√™me entre les pannes et les op√©rations normales. Le nettoyage a impliqu√© la suppression des colonnes avec un grand nombre de valeurs manquantes et une gestion sp√©cifique des valeurs `NaN`.

#### ¬∑ Feature Engineering
Pour capturer les tendances dynamiques des donn√©es de capteurs, de nouvelles caract√©ristiques temporelles ont √©t√© cr√©√©es, notamment des **moyennes glissantes (`rolling averages`)**. Cette √©tape est cruciale pour que le mod√®le puisse apprendre non seulement √† partir des valeurs instantan√©es, mais aussi de leur √©volution dans le temps.

#### ¬∑ Mod√©lisation avec Apprentissage d'Ensemble (Ensemble Learning)
Pour am√©liorer la robustesse et la pr√©cision des pr√©dictions, des m√©thodes d'ensemble learning ont √©t√© appliqu√©es :
-   **Bagging :** Un mod√®le **Random Forest** a √©t√© entra√Æn√© comme approche de r√©f√©rence.
-   **Boosting :** Des mod√®les plus puissants comme **Gradient Boosting** et **XGBoost** ont √©t√© mis en ≈ìuvre pour am√©liorer les performances, en particulier dans ce contexte de donn√©es d√©s√©quilibr√©es.

#### ¬∑ Gestion des Donn√©es D√©s√©quilibr√©es (Handling Imbalanced Data)
C'est le c≈ìur du projet. Plusieurs techniques ont √©t√© combin√©es pour forcer le mod√®le √† pr√™ter attention √† la classe minoritaire (pannes) :
1.  **Sur-√©chantillonnage (Over-sampling) :** La technique **SMOTE** (Synthetic Minority Over-sampling Technique) a √©t√© utilis√©e pour cr√©er synth√©tiquement de nouveaux exemples de pannes.
2.  **Sous-√©chantillonnage (Under-sampling) :** La classe majoritaire (op√©rations normales) a √©t√© sous-√©chantillonn√©e pour r√©duire le d√©s√©quilibre.
3.  **Apprentissage sensible aux co√ªts (Cost-Sensitive Learning) :** Des poids ont √©t√© ajust√©s dans les mod√®les (ex: `scale_pos_weight` dans XGBoost) pour p√©naliser plus lourdement les erreurs de classification sur les pannes.

#### ¬∑ Fine tuning
- Pour atteindre les meilleures performances, une comparaison a √©t√© men√©e sur diff√©rents jeux d'hyperparam√®tres pour les techniques de gestion du d√©s√©quilibre.
- Pour le fine tuning des mod√®les entra√Æn√©s, 2 GridSearch ont √©t√© appliqu√©es, l'une ayant pour objectif de maximiser le f1-score de chaque classe et l'autre de maximiser le rappel de chaque classe.

#### ¬∑ √âvaluation
√âtant donn√© le d√©s√©quilibre des classes, la simple `accuracy` n'est pas une m√©trique pertinente. L'√©valuation s'est concentr√©e sur :
-   **AUC-ROC :** Pour mesurer la capacit√© du mod√®le √† discriminer entre les deux classes.
-   **F1-Score, Pr√©cision et Rappel (Precision & Recall) :** Pour √©valuer le compromis entre la d√©tection correcte des pannes et le risque de fausses alertes.

***

### üìä R√©sultats
#### ¬∑ Performances des mod√®les
Les mod√®les de base entra√Æn√©s sur les donn√©es brutes ont montr√© une faible capacit√© √† d√©tecter les pannes, avec des F1-Scores tr√®s bas (autour de 0.14-0.21). Apr√®s l'application des techniques de r√©-√©chantillonnage et d'apprentissage sensible aux co√ªts, le mod√®le **XGBoost optimis√© a atteint un F1-Score de 0.60 et une pr√©cision de 0.80** pour la classe "panne" sur les donn√©es de test, tout en gardant de tr√®s bons scores pour l'autre classe.

#### ¬∑ Comparaison des approches
La comparaison a clairement d√©montr√© l'am√©lioration drastique apport√©e par les strat√©gies de gestion de donn√©es d√©s√©quilibr√©es. L'approche combinant SMOTE et le sous-√©chantillonnage a fourni les meilleurs r√©sultats. Le mod√®le **XGBoost** s'est av√©r√© sup√©rieur aux autres, offrant le meilleur compromis entre la d√©tection des pannes r√©elles et la minimisation des fausses alertes.

#### ¬∑ Interpr√©tation des r√©sultats
Les r√©sultats confirment que les techniques d'ensemble comme XGBoost, combin√©es √† une gestion rigoureuse du d√©s√©quilibre des classes, sont essentielles pour construire un syst√®me de maintenance pr√©dictive efficace. Le mod√®le final est capable d'identifier une part significative des pannes imminentes, permettant une intervention proactive.

***

### üí° Ce que j'ai appris
#### ¬∑ Comp√©tences acquises ou renforc√©es
-   **Apprentissage d'Ensemble :** Mise en ≈ìuvre et comparaison de techniques de Bagging (Random Forest) et de Boosting (Gradient Boosting, XGBoost) pour un probl√®me de classification complexe.
-   **Gestion de Donn√©es D√©s√©quilibr√©es :** Ma√Ætrise des techniques fondamentales comme SMOTE, le sous-√©chantillonnage et l'apprentissage sensible aux co√ªts pour des probl√®mes r√©els o√π la classe d'int√©r√™t est rare.
-   **Feature Engineering pour S√©ries Temporelles :** Manipulation de s√©ries temporelles et cr√©ation de caract√©ristiques pertinentes (moyennes glissantes) pour am√©liorer le pouvoir pr√©dictif des mod√®les.
-   **√âvaluation de Mod√®les en Conditions D√©s√©quilibr√©es :** Utilisation et interpr√©tation de m√©triques adapt√©es au contexte (AUC-ROC, F1-Score, Rappel)